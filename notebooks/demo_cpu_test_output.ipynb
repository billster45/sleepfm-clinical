{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: All data in this repo is synthetically made including sleep stage annotations, demographics or diseases. The data is for demo purposes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:26.856542Z",
     "iopub.status.busy": "2026-01-06T18:26:26.856149Z",
     "iopub.status.idle": "2026-01-06T18:26:26.928390Z",
     "shell.execute_reply": "2026-01-06T18:26:26.928109Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Details\n",
    "\n",
    "\n",
    "Before running this notebook, please preprocess your PSG files using the scripts provided in `sleepfm/preprocessing`. Note that PSG recordings may contain different sets of channels across datasets. The predefined channel–modality mappings used in this project are specified in `sleepfm/configs/channel_groups.json`.\n",
    "\n",
    "Although we have attempted to make this mapping as comprehensive as possible, we strongly recommend reviewing the channels present in your specific PSG data. In consultation with domain experts, you should group any additional or dataset-specific channels into the appropriate modality categories and update `channel_groups.json` accordingly. This step is critical to ensure that all channels are correctly aligned with their intended modalities during preprocessing and downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:26.930060Z",
     "iopub.status.busy": "2026-01-06T18:26:26.929960Z",
     "iopub.status.idle": "2026-01-06T18:26:28.459339Z",
     "shell.execute_reply": "2026-01-06T18:26:28.458991Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../sleepfm\")\n",
    "from preprocessing.preprocessing import EDFToHDF5Converter\n",
    "from models.dataset import SetTransformerDataset, collate_fn\n",
    "from models.models import SetTransformer, SleepEventLSTMClassifier, DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
    "import h5py\n",
    "from utils import load_config, load_data, save_data, count_parameters\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 0: Preprocessing EDF files\n",
    "\n",
    "Note: This is just a demo notebook that preprocesses a single, specific file. run `sleepfm/preprocessing/preprocessing.sh` with appropriate folders to generate multiple preprocessed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:28.460785Z",
     "iopub.status.busy": "2026-01-06T18:26:28.460652Z",
     "iopub.status.idle": "2026-01-06T18:26:28.478481Z",
     "shell.execute_reply": "2026-01-06T18:26:28.478175Z"
    }
   },
   "outputs": [],
   "source": [
    "base_save_path = \"demo_data\"\n",
    "os.makedirs(base_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:28.479604Z",
     "iopub.status.busy": "2026-01-06T18:26:28.479534Z",
     "iopub.status.idle": "2026-01-06T18:26:29.224754Z",
     "shell.execute_reply": "2026-01-06T18:26:29.224493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-06 18:26:28.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mread_edf\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mreading edf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/billcockerill/Documents/sleepfm-clinical/notebooks/demo_data/demo_psg.edf...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF file detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 2234623  =      0.000 ...  8728.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-06 18:26:28.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mresample_signals\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1mresampling signals\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-06 18:26:28.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36msave_to_hdf5\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1msaving hdf5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/edf_root\"      # dummy root not used for a single file conversion\n",
    "target_dir = \"/note\"    # dummy target not used for a single file conversion\n",
    "\n",
    "edf_path = \"demo_data/demo_psg.edf\"\n",
    "hdf5_path = os.path.join(base_save_path, \"demo_psg.hdf5\")\n",
    "\n",
    "converter = EDFToHDF5Converter(\n",
    "    root_dir=root_dir,\n",
    "    target_dir=target_dir,\n",
    "    resample_rate=128\n",
    ")\n",
    "\n",
    "# run for single file conversion\n",
    "converter.convert(edf_path, hdf5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Generating embeddings from SleepFM pretrained model\n",
    "\n",
    "Here we show generating embedding for 1 demno PSG. To see full script, please check `sleepfm/pipeline/generate_embeddings.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.226022Z",
     "iopub.status.busy": "2026-01-06T18:26:29.225934Z",
     "iopub.status.idle": "2026-01-06T18:26:29.243266Z",
     "shell.execute_reply": "2026-01-06T18:26:29.243049Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"../sleepfm/checkpoints/model_base\"\n",
    "channel_groups_path = \"../sleepfm/configs/channel_groups.json\"\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "channel_groups = load_data(channel_groups_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.244449Z",
     "iopub.status.busy": "2026-01-06T18:26:29.244375Z",
     "iopub.status.idle": "2026-01-06T18:26:29.260260Z",
     "shell.execute_reply": "2026-01-06T18:26:29.260014Z"
    }
   },
   "outputs": [],
   "source": [
    "modality_types = config[\"modality_types\"]\n",
    "in_channels = config[\"in_channels\"]\n",
    "patch_size = config[\"patch_size\"]\n",
    "embed_dim = config[\"embed_dim\"]\n",
    "num_heads = config[\"num_heads\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "pooling_head = config[\"pooling_head\"]\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.261470Z",
     "iopub.status.busy": "2026-01-06T18:26:29.261399Z",
     "iopub.status.idle": "2026-01-06T18:26:29.286204Z",
     "shell.execute_reply": "2026-01-06T18:26:29.286021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Trainable parameters: 4.44 million\n",
      "Number of layers: 93\n"
     ]
    }
   ],
   "source": [
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(in_channels, patch_size, embed_dim, num_heads, num_layers, pooling_head=pooling_head, dropout=dropout)\n",
    "\n",
    "# Auto-detect device (CUDA if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.287173Z",
     "iopub.status.busy": "2026-01-06T18:26:29.287110Z",
     "iopub.status.idle": "2026-01-06T18:26:29.310381Z",
     "shell.execute_reply": "2026-01-06T18:26:29.310173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformer(\n",
       "  (patch_embedding): Tokenizer(\n",
       "    (tokenizer): Sequential(\n",
       "      (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): LayerNorm((4, 320), eps=1e-05, elementwise_affine=True)\n",
       "      (4): Conv1d(4, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ELU(alpha=1.0)\n",
       "      (7): LayerNorm((8, 160), eps=1e-05, elementwise_affine=True)\n",
       "      (8): Conv1d(8, 16, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ELU(alpha=1.0)\n",
       "      (11): LayerNorm((16, 80), eps=1e-05, elementwise_affine=True)\n",
       "      (12): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ELU(alpha=1.0)\n",
       "      (15): LayerNorm((32, 40), eps=1e-05, elementwise_affine=True)\n",
       "      (16): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (18): ELU(alpha=1.0)\n",
       "      (19): LayerNorm((64, 20), eps=1e-05, elementwise_affine=True)\n",
       "      (20): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ELU(alpha=1.0)\n",
       "      (23): LayerNorm((128, 10), eps=1e-05, elementwise_affine=True)\n",
       "      (24): AdaptiveAvgPool1d(output_size=1)\n",
       "      (25): Flatten(start_dim=1, end_dim=-1)\n",
       "      (26): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (spatial_pooling): AttentionPooling(\n",
       "    (transformer_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_pooling): AttentionPooling(\n",
       "    (transformer_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(model_path, \"best.pt\"), map_location=device)\n",
    "\n",
    "# Handle state dict keys - remove 'module.' prefix if loading without DataParallel\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "if device.type == \"cpu\" and list(state_dict.keys())[0].startswith(\"module.\"):\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "elif device.type == \"cuda\" and not list(state_dict.keys())[0].startswith(\"module.\"):\n",
    "    state_dict = {\"module.\" + k: v for k, v in state_dict.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.311401Z",
     "iopub.status.busy": "2026-01-06T18:26:29.311344Z",
     "iopub.status.idle": "2026-01-06T18:26:29.327511Z",
     "shell.execute_reply": "2026-01-06T18:26:29.327294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'model': 'SetTransformer',\n",
       " 'in_channels': 1,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 1,\n",
       " 'lr': 0.001,\n",
       " 'lr_step_period': 2,\n",
       " 'gamma': 0.1,\n",
       " 'temperature': 0.0,\n",
       " 'momentum': 0.9,\n",
       " 'num_workers': 16,\n",
       " 'embed_dim': 128,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 6,\n",
       " 'pooling_head': 8,\n",
       " 'dropout': 0.3,\n",
       " 'split_path': 'path_to_/dataset_split.json',\n",
       " 'save_path': 'path_to_/models',\n",
       " 'weight_decay': 0.0,\n",
       " 'mode': 'leave_one_out',\n",
       " 'save_iter': 5000,\n",
       " 'eval_iter': 5000,\n",
       " 'log_interval': 100,\n",
       " 'use_wandb': True,\n",
       " 'BAS_CHANNELS': 10,\n",
       " 'RESP_CHANNELS': 7,\n",
       " 'EKG_CHANNELS': 2,\n",
       " 'EMG_CHANNELS': 4,\n",
       " 'max_files': None,\n",
       " 'val_size': 100,\n",
       " 'sampling_duration': 5,\n",
       " 'sampling_freq': 128,\n",
       " 'patch_size': 640,\n",
       " 'modality_types': ['BAS', 'RESP', 'EKG', 'EMG']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:29.328516Z",
     "iopub.status.busy": "2026-01-06T18:26:29.328452Z",
     "iopub.status.idle": "2026-01-06T18:26:30.304856Z",
     "shell.execute_reply": "2026-01-06T18:26:30.304580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Indexing files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Indexing files: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Indexing files: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_psg.hdf5\")]\n",
    "dataset = SetTransformerDataset(config, channel_groups, hdf5_paths=hdf5_paths, split=\"test\")\n",
    "\n",
    "# Use num_workers=0 for CPU/macOS compatibility\n",
    "num_workers = 0 if device.type == \"cpu\" else 1\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                            batch_size=16, \n",
    "                                            num_workers=num_workers, \n",
    "                                            shuffle=False, \n",
    "                                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:30.306059Z",
     "iopub.status.busy": "2026-01-06T18:26:30.305985Z",
     "iopub.status.idle": "2026-01-06T18:26:30.326577Z",
     "shell.execute_reply": "2026-01-06T18:26:30.326300Z"
    }
   },
   "outputs": [],
   "source": [
    "output = os.path.join(base_save_path, \"demo_emb\")\n",
    "output_5min_agg = os.path.join(base_save_path, \"demo_5min_agg_emb\")\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(output_5min_agg, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:30.327854Z",
     "iopub.status.busy": "2026-01-06T18:26:30.327779Z",
     "iopub.status.idle": "2026-01-06T18:26:31.551413Z",
     "shell.execute_reply": "2026-01-06T18:26:31.551171Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch in dataloader:\n",
    "            batch_data, mask_list, file_paths, dset_names_list, chunk_starts = batch\n",
    "            (bas, resp, ekg, emg) = batch_data\n",
    "            (mask_bas, mask_resp, mask_ekg, mask_emg) = mask_list\n",
    "\n",
    "            bas = bas.to(device, dtype=torch.float)\n",
    "            resp = resp.to(device, dtype=torch.float)\n",
    "            ekg = ekg.to(device, dtype=torch.float)\n",
    "            emg = emg.to(device, dtype=torch.float)\n",
    "\n",
    "            mask_bas = mask_bas.to(device, dtype=torch.bool)\n",
    "            mask_resp = mask_resp.to(device, dtype=torch.bool)\n",
    "            mask_ekg = mask_ekg.to(device, dtype=torch.bool)\n",
    "            mask_emg = mask_emg.to(device, dtype=torch.bool)\n",
    "\n",
    "            embeddings = [\n",
    "                model(bas, mask_bas),\n",
    "                model(resp, mask_resp),\n",
    "                model(ekg, mask_ekg),\n",
    "                model(emg, mask_emg),\n",
    "            ]\n",
    "\n",
    "            # Model gives two kinds of embeddings. Granular 5 second-level embeddings and aggregated 5 minute-level embeddings. We save both of them below. \n",
    "\n",
    "            embeddings_new = [e[0].unsqueeze(1) for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output_5min_agg, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5 * 60)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "\n",
    "            embeddings_new = [e[1] for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Sleep Staging\n",
    "\n",
    "Note that below, we are using our finetuned sleep staging model. It is always a good idea to finetune our model on your specific data, even if you only have a handful of sample, so that the model can adapt to your specific data distribution. Script to finetune your sleep staging model head is given in `sleepfm/pipeline/finetune_sleep_staging.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.552442Z",
     "iopub.status.busy": "2026-01-06T18:26:31.552365Z",
     "iopub.status.idle": "2026-01-06T18:26:31.575689Z",
     "shell.execute_reply": "2026-01-06T18:26:31.575404Z"
    }
   },
   "outputs": [],
   "source": [
    "sleep_staging_model_path = \"../sleepfm/checkpoints/model_sleep_staging\"\n",
    "sleep_staging_config = load_data(os.path.join(sleep_staging_model_path, \"config.json\"))\n",
    "\n",
    "sleep_staging_model_params = sleep_staging_config['model_params']\n",
    "sleep_staging_model_class = getattr(sys.modules[__name__], sleep_staging_config['model'])\n",
    "\n",
    "sleep_staging_model = sleep_staging_model_class(**sleep_staging_model_params).to(device)\n",
    "sleep_staging_model_name = type(sleep_staging_model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.576768Z",
     "iopub.status.busy": "2026-01-06T18:26:31.576695Z",
     "iopub.status.idle": "2026-01-06T18:26:31.593936Z",
     "shell.execute_reply": "2026-01-06T18:26:31.593721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU (no CUDA available)\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    sleep_staging_model = nn.DataParallel(sleep_staging_model)\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "else:\n",
    "    print(f\"Using CPU (no CUDA available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.594983Z",
     "iopub.status.busy": "2026-01-06T18:26:31.594920Z",
     "iopub.status.idle": "2026-01-06T18:26:31.611999Z",
     "shell.execute_reply": "2026-01-06T18:26:31.611807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: SleepEventLSTMClassifier\n",
      "Trainable parameters: 1.19 million\n",
      "Number of layers: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model initialized: {sleep_staging_model_name}\")\n",
    "total_layers, total_params = count_parameters(sleep_staging_model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.612956Z",
     "iopub.status.busy": "2026-01-06T18:26:31.612893Z",
     "iopub.status.idle": "2026-01-06T18:26:31.634240Z",
     "shell.execute_reply": "2026-01-06T18:26:31.634003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_staging_checkpoint_path = os.path.join(sleep_staging_model_path, \"best.pth\")\n",
    "sleep_staging_checkpoint = torch.load(sleep_staging_checkpoint_path, map_location=device)\n",
    "\n",
    "# Handle state dict keys for CPU/GPU compatibility\n",
    "if device.type == \"cpu\" and list(sleep_staging_checkpoint.keys())[0].startswith(\"module.\"):\n",
    "    sleep_staging_checkpoint = {k.replace(\"module.\", \"\"): v for k, v in sleep_staging_checkpoint.items()}\n",
    "elif device.type == \"cuda\" and not list(sleep_staging_checkpoint.keys())[0].startswith(\"module.\"):\n",
    "    sleep_staging_checkpoint = {\"module.\" + k: v for k, v in sleep_staging_checkpoint.items()}\n",
    "\n",
    "sleep_staging_model.load_state_dict(sleep_staging_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions for loading data for sleep staging. You can find similar functions within `sleepfm/models/dataset.py`. You may need to modify it slightly based on your usecase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.635347Z",
     "iopub.status.busy": "2026-01-06T18:26:31.635278Z",
     "iopub.status.idle": "2026-01-06T18:26:31.659619Z",
     "shell.execute_reply": "2026-01-06T18:26:31.659338Z"
    }
   },
   "outputs": [],
   "source": [
    "class SleepEventClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        channel_groups,\n",
    "        hdf5_paths,\n",
    "        label_files,\n",
    "        split=\"train\",\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "        self.context = int(self.config[\"context\"])\n",
    "        self.channel_like = self.config[\"channel_like\"]\n",
    "\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        # --- Build label lookup: {study_id: label_csv_path} ---\n",
    "        # study_id = filename without extension, e.g. \"SSC_12345\"\n",
    "        labels_dict = {\n",
    "            os.path.basename(p).rsplit(\".\", 1)[0]: p\n",
    "            for p in label_files\n",
    "            if os.path.exists(p)\n",
    "        }\n",
    "\n",
    "        # --- Filter to HDF5s that exist and have a matching label file ---\n",
    "        hdf5_paths = [p for p in hdf5_paths if os.path.exists(p)]\n",
    "        hdf5_paths = [\n",
    "            p for p in hdf5_paths\n",
    "            if os.path.basename(p).rsplit(\".\", 1)[0] in labels_dict\n",
    "        ]\n",
    "\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[: config[\"max_files\"]]\n",
    "\n",
    "        self.hdf5_paths = hdf5_paths\n",
    "        self.labels_dict = labels_dict\n",
    "\n",
    "        # --- Build index map ---\n",
    "        # Each item is (hdf5_path, label_path, start_index)\n",
    "        if self.context == -1:\n",
    "            self.index_map = [\n",
    "                (p, labels_dict[os.path.basename(p).rsplit(\".\", 1)[0]], -1)\n",
    "                for p in self.hdf5_paths\n",
    "            ]\n",
    "        else:\n",
    "            self.index_map = []\n",
    "            loop = tqdm(self.hdf5_paths, total=len(self.hdf5_paths), desc=f\"Indexing {split} data\")\n",
    "            for hdf5_file_path in loop:\n",
    "                file_prefix = os.path.basename(hdf5_file_path).rsplit(\".\", 1)[0]\n",
    "                label_path = labels_dict[file_prefix]\n",
    "\n",
    "                with h5py.File(hdf5_file_path, \"r\") as hf:\n",
    "                    dset_names = list(hf.keys())\n",
    "                    if len(dset_names) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Use first dataset to define length (same as your original behavior)\n",
    "                    first_name = dset_names[0]\n",
    "                    dataset_length = hf[first_name].shape[0]\n",
    "\n",
    "                for i in range(0, dataset_length, self.context):\n",
    "                    self.index_map.append((hdf5_file_path, label_path, i))\n",
    "\n",
    "        # If you have logger, keep; otherwise you can remove these.\n",
    "        # logger.info(f\"Number of files in {split} set: {len(self.hdf5_paths)}\")\n",
    "        # logger.info(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def get_index_map(self):\n",
    "        return self.index_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, label_path, start_index = self.index_map[idx]\n",
    "\n",
    "        labels_df = pd.read_csv(label_path)\n",
    "        labels_df[\"StageNumber\"] = labels_df[\"StageNumber\"].replace(-1, 0)\n",
    "\n",
    "        y_data = labels_df[\"StageNumber\"].to_numpy()\n",
    "        if self.context != -1:\n",
    "            y_data = y_data[start_index : start_index + self.context]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, \"r\") as hf:\n",
    "            dset_names = list(hf.keys())\n",
    "\n",
    "            for dataset_name in dset_names:\n",
    "                if dataset_name in self.channel_like:\n",
    "                    if self.context == -1:\n",
    "                        x_data.append(hf[dataset_name][:])\n",
    "                    else:\n",
    "                        x_data.append(hf[dataset_name][start_index : start_index + self.context])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        x_data = np.array(x_data)  # (C, T, F) assuming each channel returns (T, F)\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "        min_length = min(x_data.shape[1], len(y_data))\n",
    "        x_data = x_data[:, :min_length, :]\n",
    "        y_data = y_data[:min_length]\n",
    "\n",
    "        return x_data, y_data, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def sleep_event_finetune_full_collate_fn(batch):\n",
    "    x_data, y_data, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    max_seq_len_temp = max([item.size(1) for item in x_data])\n",
    "    # Determine the max sequence length for padding\n",
    "    if max_seq_len_list[0] is None:\n",
    "        max_seq_len = max_seq_len_temp\n",
    "    else:\n",
    "        max_seq_len = min(max_seq_len_temp, max_seq_len_list[0])\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_y_data = []\n",
    "    padded_mask = []\n",
    "\n",
    "    for x_item, y_item in zip(x_data, y_data):\n",
    "\n",
    "        # first non-zero index of y_data\n",
    "        #print(y_item.shape)\n",
    "\n",
    "\n",
    "        tgt_sleep_no_sleep = np.where(y_item > 0, 1, 0)\n",
    "        moving_avg_tgt_sleep_no_sleep = np.convolve(tgt_sleep_no_sleep, np.ones(1080)/1080, mode='valid')\n",
    "        try:\n",
    "            first_non_zero_index = np.where(moving_avg_tgt_sleep_no_sleep > 0.5)[0][0]\n",
    "        except IndexError:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "\n",
    "\n",
    "        #non_zero_indices = (y_item != 0).nonzero(as_tuple=True)[0]\n",
    "        #first_non_zero_index = non_zero_indices[0].item() - 20\n",
    "        if first_non_zero_index < 0:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "        #first_non_zero_index = 0\n",
    "\n",
    "        #print(f\"First non-zero index of y_data: {first_non_zero_index}\")\n",
    "        # Get the shape of x_item\n",
    "        c, s, e = x_item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len + first_non_zero_index)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor for x_data\n",
    "        padded_x_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        #print(f\"Shape of x_item: {x_item[:c, first_non_zero_index:s, :e].shape}\")\n",
    "        padded_x_item[:c, :s-first_non_zero_index, :e] = x_item[:c, first_non_zero_index:s, :e]\n",
    "        mask[:c, :s-first_non_zero_index] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        # Pad y_data with zeros to match max_seq_len\n",
    "        padded_y_item = torch.zeros(max_seq_len)\n",
    "        padded_y_item[:s-first_non_zero_index] = y_item[first_non_zero_index:s]\n",
    "\n",
    "        # Append padded items to lists\n",
    "        padded_x_data.append(padded_x_item)\n",
    "        padded_y_data.append(padded_y_item)\n",
    "        padded_mask.append(mask)\n",
    "\n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    y_data = torch.stack(padded_y_data)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "\n",
    "    '''\n",
    "    for y_data_mini in y_data:\n",
    "        unique_labels = torch.unique(y_data_mini)\n",
    "        print(f\"Unique labels in batch: {unique_labels}\")\n",
    "    '''\n",
    "\n",
    "    return x_data, y_data, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.660721Z",
     "iopub.status.busy": "2026-01-06T18:26:31.660653Z",
     "iopub.status.idle": "2026-01-06T18:26:31.678433Z",
     "shell.execute_reply": "2026-01-06T18:26:31.678128Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "label_files = [os.path.join(base_save_path, \"demo_psg.csv\")]\n",
    "test_dataset = SleepEventClassificationDataset(sleep_staging_config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, label_files=label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.679513Z",
     "iopub.status.busy": "2026-01-06T18:26:31.679457Z",
     "iopub.status.idle": "2026-01-06T18:26:31.695865Z",
     "shell.execute_reply": "2026-01-06T18:26:31.695572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use num_workers=0 for CPU/macOS compatibility\n",
    "num_workers = 0 if device.type == \"cpu\" else 1\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=num_workers, collate_fn=sleep_event_finetune_full_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.696917Z",
     "iopub.status.busy": "2026-01-06T18:26:31.696856Z",
     "iopub.status.idle": "2026-01-06T18:26:31.867542Z",
     "shell.execute_reply": "2026-01-06T18:26:31.867319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation loop at the end of each epoch\n",
    "model.eval()\n",
    "all_targets = []\n",
    "all_logits = []\n",
    "all_outputs = []\n",
    "all_masks = []\n",
    "all_paths = []\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for (x_data, y_data, padded_matrix, hdf5_path_list) in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, y_data, padded_matrix, hdf5_path_list = x_data.to(device), y_data.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs, mask = sleep_staging_model(x_data, padded_matrix)\n",
    "        all_targets.append(y_data.cpu().numpy())\n",
    "        all_outputs.append(torch.softmax(outputs, dim=-1).cpu().numpy())\n",
    "        all_logits.append(outputs.cpu().numpy())\n",
    "        all_masks.append(mask.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "\n",
    "save_path = os.path.join(base_save_path, \"demo_sleep_staging\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "targets_path = os.path.join(save_path, \"all_targets.pickle\")\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "logits_path = os.path.join(save_path, \"all_logits.pickle\")\n",
    "mask_path = os.path.join(save_path, \"all_masks.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_targets, targets_path)\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_logits, logits_path)\n",
    "save_data(all_masks, mask_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.868598Z",
     "iopub.status.busy": "2026-01-06T18:26:31.868523Z",
     "iopub.status.idle": "2026-01-06T18:26:31.885546Z",
     "shell.execute_reply": "2026-01-06T18:26:31.885313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1740, 5), (1, 1740))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].shape, all_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.886527Z",
     "iopub.status.busy": "2026-01-06T18:26:31.886459Z",
     "iopub.status.idle": "2026-01-06T18:26:31.906860Z",
     "shell.execute_reply": "2026-01-06T18:26:31.906642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits), len(all_outputs), len(all_targets), len(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.907816Z",
     "iopub.status.busy": "2026-01-06T18:26:31.907752Z",
     "iopub.status.idle": "2026-01-06T18:26:31.928594Z",
     "shell.execute_reply": "2026-01-06T18:26:31.928387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1740, 5), (1, 1740, 5), (1, 1740), (1, 1740))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape, all_outputs[0].shape, all_targets[0].shape, all_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.929579Z",
     "iopub.status.busy": "2026-01-06T18:26:31.929521Z",
     "iopub.status.idle": "2026-01-06T18:26:31.947699Z",
     "shell.execute_reply": "2026-01-06T18:26:31.947429Z"
    }
   },
   "outputs": [],
   "source": [
    "all_logits_flat = [logits.reshape(-1, logits.shape[-1]) for logits in all_logits]\n",
    "all_outputs_flat = [outputs.reshape(-1, outputs.shape[-1]) for outputs in all_outputs]\n",
    "all_targets_flat = [targets.reshape(-1) for targets in all_targets]\n",
    "all_masks_flat = [mask.reshape(-1) for mask in all_masks]\n",
    "\n",
    "# Convert lists of flattened arrays to single concatenated arrays if desired\n",
    "all_logits_flat = np.concatenate(all_logits_flat, axis=0)\n",
    "all_outputs_flat = np.concatenate(all_outputs_flat, axis=0)\n",
    "all_targets_flat = np.concatenate(all_targets_flat, axis=0)\n",
    "all_masks_flat = np.concatenate(all_masks_flat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.948753Z",
     "iopub.status.busy": "2026-01-06T18:26:31.948693Z",
     "iopub.status.idle": "2026-01-06T18:26:31.970735Z",
     "shell.execute_reply": "2026-01-06T18:26:31.970536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1740, 5), (1740, 5), (1740,), (1740,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits_flat.shape, all_outputs_flat.shape, all_targets_flat.shape, all_masks_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.971702Z",
     "iopub.status.busy": "2026-01-06T18:26:31.971642Z",
     "iopub.status.idle": "2026-01-06T18:26:31.993144Z",
     "shell.execute_reply": "2026-01-06T18:26:31.992909Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_filter = all_masks_flat == 0\n",
    "\n",
    "# Apply the mask to each flattened array\n",
    "all_logits_filtered = all_logits_flat[mask_filter]\n",
    "all_outputs_filtered = all_outputs_flat[mask_filter]\n",
    "all_targets_filtered = all_targets_flat[mask_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:31.994198Z",
     "iopub.status.busy": "2026-01-06T18:26:31.994141Z",
     "iopub.status.idle": "2026-01-06T18:26:32.018440Z",
     "shell.execute_reply": "2026-01-06T18:26:32.018203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.367816091954023,\n",
       " 1.0: 0.1511494252873563,\n",
       " 4.0: 0.16839080459770114,\n",
       " 3.0: 0.15402298850574714,\n",
       " 2.0: 0.15862068965517243}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(all_targets_filtered)\n",
    "total = sum(counts.values())\n",
    "prevalence_dict = {cls: count / total for cls, count in counts.items()}\n",
    "prevalence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.019396Z",
     "iopub.status.busy": "2026-01-06T18:26:32.019332Z",
     "iopub.status.idle": "2026-01-06T18:26:32.039352Z",
     "shell.execute_reply": "2026-01-06T18:26:32.039055Z"
    }
   },
   "outputs": [],
   "source": [
    "class_labels = [\"Wake\", \"Stage 1\", \"Stage 2\", \"Stage 3\", \"REM\"]\n",
    "# class_labels = [\"No-Apnea\", \"Apnea\"]\n",
    "class_mapping = {label: idx for idx, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.040465Z",
     "iopub.status.busy": "2026-01-06T18:26:32.040395Z",
     "iopub.status.idle": "2026-01-06T18:26:32.596162Z",
     "shell.execute_reply": "2026-01-06T18:26:32.595964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Wake: 0.538\n",
      "F1 Score for Stage 1: 0.000\n",
      "F1 Score for Stage 2: 0.000\n",
      "F1 Score for Stage 3: 0.000\n",
      "F1 Score for REM: 0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Get predicted labels (argmax on probabilities)\n",
    "predicted_labels = np.argmax(all_outputs_filtered, axis=1)\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Step 2: Compute F1 score for each class\n",
    "f1_scores = f1_score(all_targets_filtered, predicted_labels, average=None, labels=range(len(class_labels)))\n",
    "for idx, label in enumerate(class_labels):\n",
    "    print(f\"F1 Score for {label}: {f1_scores[idx]:.3f}\")\n",
    "\n",
    "# Step 3: Create a confusion matrix and normalize it by row to get percentages\n",
    "conf_matrix = confusion_matrix(all_targets_filtered, predicted_labels, labels=range(len(class_labels)))\n",
    "conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "# Plotting the confusion matrix with percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    conf_matrix_percent,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    "    annot_kws={\"size\": fontsize},  # Font size for numbers inside the heatmap\n",
    "    cbar_kws={\"shrink\": 1},  # Adjust colorbar size\n",
    ")\n",
    "\n",
    "# Customizing axis labels and ticks\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=fontsize)\n",
    "plt.ylabel(\"True Labels\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=12, ha=\"center\")  # Font size for x-axis tick labels with rotation\n",
    "plt.yticks(fontsize=12)  # Font size for y-axis tick labels\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.597184Z",
     "iopub.status.busy": "2026-01-06T18:26:32.597114Z",
     "iopub.status.idle": "2026-01-06T18:26:32.619332Z",
     "shell.execute_reply": "2026-01-06T18:26:32.619036Z"
    }
   },
   "outputs": [],
   "source": [
    "disease_model_path = \"../sleepfm/checkpoints/model_diagnosis\"\n",
    "config = load_data(os.path.join(disease_model_path, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.620432Z",
     "iopub.status.busy": "2026-01-06T18:26:32.620367Z",
     "iopub.status.idle": "2026-01-06T18:26:32.646729Z",
     "shell.execute_reply": "2026-01-06T18:26:32.646425Z"
    }
   },
   "outputs": [],
   "source": [
    "config[\"model_params\"][\"dropout\"] = 0.0\n",
    "model_params = config['model_params']\n",
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(**model_params).to(device)\n",
    "model_name = type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.647817Z",
     "iopub.status.busy": "2026-01-06T18:26:32.647759Z",
     "iopub.status.idle": "2026-01-06T18:26:32.665813Z",
     "shell.execute_reply": "2026-01-06T18:26:32.665599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU (no CUDA available)\n",
      "Model initialized: DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
      "Trainable parameters: 0.91 million\n",
      "Number of layers: 15\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    model = nn.DataParallel(model)\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "else:\n",
    "    print(f\"Using CPU (no CUDA available)\")\n",
    "\n",
    "print(f\"Model initialized: {model_name}\")\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.666786Z",
     "iopub.status.busy": "2026-01-06T18:26:32.666729Z",
     "iopub.status.idle": "2026-01-06T18:26:32.689762Z",
     "shell.execute_reply": "2026-01-06T18:26:32.689541Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(disease_model_path, \"best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.690773Z",
     "iopub.status.busy": "2026-01-06T18:26:32.690718Z",
     "iopub.status.idle": "2026-01-06T18:26:32.713721Z",
     "shell.execute_reply": "2026-01-06T18:26:32.713490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Handle state dict keys for CPU/GPU compatibility\n",
    "if device.type == \"cpu\" and list(checkpoint.keys())[0].startswith(\"module.\"):\n",
    "    checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint.items()}\n",
    "elif device.type == \"cuda\" and not list(checkpoint.keys())[0].startswith(\"module.\"):\n",
    "    checkpoint = {\"module.\" + k: v for k, v in checkpoint.items()}\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.715318Z",
     "iopub.status.busy": "2026-01-06T18:26:32.714917Z",
     "iopub.status.idle": "2026-01-06T18:26:32.750494Z",
     "shell.execute_reply": "2026-01-06T18:26:32.750239Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiagnosisFinetuneFullCOXPHWithDemoDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 channel_groups,\n",
    "                 hdf5_paths=None,\n",
    "                 demo_labels_path=None,\n",
    "                 split=\"train\"):\n",
    "\n",
    "        self.config = config\n",
    "        self.channel_groups = channel_groups\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "\n",
    "        # --- Load demographic features ---\n",
    "        if not demo_labels_path:\n",
    "            demo_labels_path = config[\"demo_labels_path\"]\n",
    "\n",
    "        demo_labels_df = pd.read_csv(demo_labels_path)\n",
    "        demo_labels_df = demo_labels_df.set_index(\"Study ID\")\n",
    "        study_ids = set(demo_labels_df.index)\n",
    "\n",
    "        is_event_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"is_event.csv\"))\n",
    "        event_time_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"time_to_event.csv\"))\n",
    "\n",
    "        is_event_df = is_event_df.set_index('Study ID')\n",
    "        event_time_df = event_time_df.set_index('Study ID')\n",
    "\n",
    "        # --- Resolve HDF5 paths (explicit precedence) ---\n",
    "        if hdf5_paths:\n",
    "            # Use provided paths directly\n",
    "            hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        else:\n",
    "            # Load from split file\n",
    "            split_paths = load_data(config[\"split_path\"])[split]\n",
    "            hdf5_paths = [f for f in split_paths if os.path.exists(f)]\n",
    "\n",
    "        # Filter by available demo labels\n",
    "        hdf5_paths = [\n",
    "            f for f in hdf5_paths\n",
    "            if os.path.basename(f).split(\".\")[0] in study_ids\n",
    "        ]\n",
    "\n",
    "        # Optional truncation\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[:config[\"max_files\"]]\n",
    "\n",
    "        labels_dict = {}\n",
    "        # Loop over each study_id\n",
    "        for study_id in tqdm.tqdm(study_ids):\n",
    "            # Extract the row as a whole for both dataframes (faster than iterating over columns)\n",
    "            is_event_row = list(is_event_df.loc[study_id].values)\n",
    "            event_time_row = list(event_time_df.loc[study_id].values)\n",
    "            demo_feats = list(demo_labels_df.loc[study_id].values)\n",
    "\n",
    "            # values = [[event_time, is_event] for is_event, event_time in zip(is_event_row, event_time_row)]\n",
    "            labels_dict[study_id] = {\n",
    "                \"is_event\": is_event_row,\n",
    "                \"event_time\": event_time_row, \n",
    "                \"demo_feats\": demo_feats\n",
    "            }\n",
    "\n",
    "        # --- Build index map ---\n",
    "        self.index_map = [\n",
    "            (path, labels_dict[os.path.basename(path).split(\".\")[0]])\n",
    "            for path in hdf5_paths\n",
    "        ]\n",
    "\n",
    "        print(f\"Number of files in {split} set: {len(hdf5_paths)}\")\n",
    "        print(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        if self.total_len == 0:\n",
    "            raise ValueError(f\"No valid HDF5 files found for split='{split}'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, tte_event = self.index_map[idx]\n",
    "\n",
    "        event_time = tte_event[\"event_time\"]\n",
    "        is_event = tte_event[\"is_event\"]\n",
    "        demo_feats = tte_event[\"demo_feats\"]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, 'r') as hf:\n",
    "            dset_names = []\n",
    "            for dset_name in hf.keys():\n",
    "                if isinstance(hf[dset_name], h5py.Dataset) and dset_name in self.config[\"modality_types\"]:\n",
    "                    dset_names.append(dset_name)\n",
    "            \n",
    "            random.shuffle(dset_names)\n",
    "            for dataset_name in dset_names:\n",
    "                x_data.append(hf[dataset_name][:])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        # Convert x_data list to a single numpy array\n",
    "        x_data = np.array(x_data)\n",
    "\n",
    "        # Convert x_data to tensor\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "\n",
    "        event_time = torch.tensor(event_time, dtype=torch.float32)\n",
    "        is_event = torch.tensor(is_event) \n",
    "\n",
    "        demo_feats = torch.tensor(demo_feats, dtype=torch.float32)\n",
    "\n",
    "        return x_data, event_time, is_event, demo_feats, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def diagnosis_finetune_full_coxph_with_demo_collate_fn(batch):\n",
    "    x_data, event_time, is_event, demo_feats, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    if max_seq_len_list[0] == None:\n",
    "        max_seq_len = max([item.size(1) for item in x_data])\n",
    "    else:\n",
    "        max_seq_len = max_seq_len_list[0]\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_mask = []\n",
    "    for item in x_data:\n",
    "        c, s, e = item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor\n",
    "        padded_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        padded_item[:c, :s, :e] = item[:c, :s, :e]\n",
    "        mask[:c, :s] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        padded_x_data.append(padded_item)\n",
    "        padded_mask.append(mask)\n",
    "    \n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    event_time = torch.stack(event_time)\n",
    "    is_event = torch.stack(is_event)\n",
    "    demo_feats = torch.stack(demo_feats)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "    \n",
    "    return x_data, event_time, is_event, demo_feats, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.752183Z",
     "iopub.status.busy": "2026-01-06T18:26:32.752062Z",
     "iopub.status.idle": "2026-01-06T18:26:32.787524Z",
     "shell.execute_reply": "2026-01-06T18:26:32.787235Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(base_save_path, \"demo_diagnosis\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.788737Z",
     "iopub.status.busy": "2026-01-06T18:26:32.788665Z",
     "iopub.status.idle": "2026-01-06T18:26:32.829310Z",
     "shell.execute_reply": "2026-01-06T18:26:32.829126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in test set: 1\n",
      "Number of files to be processed in test set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "demo_labels_path = os.path.join(base_save_path, \"demo_age_gender.csv\")\n",
    "config[\"labels_path\"] = base_save_path\n",
    "\n",
    "test_dataset = DiagnosisFinetuneFullCOXPHWithDemoDataset(config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, demo_labels_path=demo_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.830411Z",
     "iopub.status.busy": "2026-01-06T18:26:32.830323Z",
     "iopub.status.idle": "2026-01-06T18:26:32.860304Z",
     "shell.execute_reply": "2026-01-06T18:26:32.860061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use num_workers=0 for CPU/macOS compatibility\n",
    "num_workers = 0 if device.type == \"cpu\" else 1\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=num_workers, collate_fn=diagnosis_finetune_full_coxph_with_demo_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:32.861766Z",
     "iopub.status.busy": "2026-01-06T18:26:32.861666Z",
     "iopub.status.idle": "2026-01-06T18:26:33.025489Z",
     "shell.execute_reply": "2026-01-06T18:26:33.025230Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billcockerill/Documents/sleepfm-clinical/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "\r",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_event_times = []\n",
    "all_is_event = []\n",
    "all_outputs = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = item\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = x_data.to(device), event_times.to(device), is_event.to(device), demo_feats.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs = model(x_data, padded_matrix, demo_feats)\n",
    "    \n",
    "        logits = outputs.cpu().numpy()\n",
    "        all_outputs.append(logits)\n",
    "        all_event_times.append(event_times.cpu().numpy())\n",
    "        all_is_event.append(is_event.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_event_times = np.concatenate(all_event_times, axis=0)\n",
    "all_is_event = np.concatenate(all_is_event, axis=0)\n",
    "all_paths = np.concatenate(all_paths)\n",
    "\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "event_times_path = os.path.join(save_path, \"all_event_times.pickle\")\n",
    "is_event_path = os.path.join(save_path, \"all_is_event.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_event_times, event_times_path)\n",
    "save_data(all_is_event, is_event_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:33.026721Z",
     "iopub.status.busy": "2026-01-06T18:26:33.026617Z",
     "iopub.status.idle": "2026-01-06T18:26:33.047141Z",
     "shell.execute_reply": "2026-01-06T18:26:33.046900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1065), (1, 1065), (1, 1065))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.shape, all_event_times.shape, all_is_event.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the model outputs, which you can then use to look for specific disease diagnosis. Nope that the shape of the output above is 1065, meaning, this model gives logprobs for 1065 conditions. We provide information about each disease index and its corresponding phecode here `sleepfm/configs/label_mapping.csv`. You can map it as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:33.048371Z",
     "iopub.status.busy": "2026-01-06T18:26:33.048290Z",
     "iopub.status.idle": "2026-01-06T18:26:33.067126Z",
     "shell.execute_reply": "2026-01-06T18:26:33.066881Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"../sleepfm/configs/label_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:33.068282Z",
     "iopub.status.busy": "2026-01-06T18:26:33.068221Z",
     "iopub.status.idle": "2026-01-06T18:26:33.086388Z",
     "shell.execute_reply": "2026-01-06T18:26:33.086084Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df[\"output\"] = all_outputs[0]\n",
    "labels_df[\"is_event\"] = all_is_event[0]\n",
    "labels_df[\"event_time\"] = all_event_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:26:33.087891Z",
     "iopub.status.busy": "2026-01-06T18:26:33.087792Z",
     "iopub.status.idle": "2026-01-06T18:26:33.112998Z",
     "shell.execute_reply": "2026-01-06T18:26:33.112764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>output</th>\n",
       "      <th>is_event</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Intestinal infection</td>\n",
       "      <td>2.382297</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Bacterial enteritis</td>\n",
       "      <td>2.941349</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Viral Enteritis</td>\n",
       "      <td>3.220718</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Septicemia</td>\n",
       "      <td>5.640466</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>Bacteremia</td>\n",
       "      <td>5.597488</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_idx phecode             phenotype    output  is_event  event_time\n",
       "0          0     8.0  Intestinal infection  2.382297         0      3845.0\n",
       "1          1     8.5   Bacterial enteritis  2.941349         0      3845.0\n",
       "2          2     8.6       Viral Enteritis  3.220718         0      3845.0\n",
       "3          3    38.0            Septicemia  5.640466         0      3845.0\n",
       "4          4    38.3            Bacteremia  5.597488         0      3845.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the output hazards from our model, and also your labels for is_event and event_times. Is_event is an indicator for if the event occured and event_time is the time to event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepfm_clinical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
